{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a8aaaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import dare\n",
    "import copy\n",
    "import math\n",
    "import random\n",
    "from enum import Enum\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools as it\n",
    "from ctgan import CTGAN\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.datasets import make_classification\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "import urllib.request as urllib\n",
    "from DebugRF import Dataset, FairnessMetric, FairnessDebuggingUsingMachineUnlearning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93868430",
   "metadata": {},
   "source": [
    "# Helper functions to generate synthetic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79b634e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FairDebuggerEfficiencyTestWithSyntheticData:\n",
    "    def __init__(self, n_instances_range, n_features_range, root_save_path, random_state = 18):\n",
    "        self.inst_rng = n_instances_range\n",
    "        self.feat_rng = n_features_range\n",
    "        self.root_save_path = root_save_path\n",
    "        self.random_state = random_state\n",
    "        \n",
    "    '''Inner dataloader class for synthetic datasets'''\n",
    "    class SyntheticDatasetLoader(Dataset):\n",
    "        def __init__(self, rootTrain, rootTest):\n",
    "            Dataset.__init__(self, rootTrain = rootTrain, rootTest = rootTest)\n",
    "            self.trainLattice, self.testLattice = self.__preprocessDatasetForCategorization(self.trainDataset),\\\n",
    "                                                  self.__preprocessDatasetForCategorization(self.testDataset)\n",
    "\n",
    "        def getDataset(self):\n",
    "            return self.dataset, self.trainDataset, self.testDataset\n",
    "\n",
    "        def getDatasetWithNormalPreprocessing(self):\n",
    "            return self.trainDataset, self.testDataset\n",
    "\n",
    "        def getDatasetWithCategorizationPreprocessing(self, decodeAttributeValues = True):\n",
    "            return self.trainLattice, self.testLattice\n",
    "\n",
    "        def __preprocessDatasetForCategorization(self, dataset):\n",
    "            df = copy.deepcopy(dataset)\n",
    "            for col in df.columns:\n",
    "                if col != \"target\":\n",
    "                    df[col] = df[col].astype(str)\n",
    "            return df\n",
    "        \n",
    "    '''Helper Functions'''\n",
    "    def __establishCardinality(self, data, cardinality):\n",
    "        normData = minmax_scale(data, \n",
    "                                feature_range = (0, 1), \n",
    "                                axis = 0)\n",
    "        columnData = copy.deepcopy(np.transpose(normData))\n",
    "        for idx, _ in enumerate(columnData):\n",
    "            if idx == 0:\n",
    "                columnData[idx][columnData[idx]>=0.5] = 1\n",
    "                columnData[idx][columnData[idx]<0.5] = 0\n",
    "                columnData[idx] = columnData[idx].astype(int)\n",
    "            else:\n",
    "                intervals = np.linspace(0, 1, cardinality + 1) \n",
    "                label = 2\n",
    "                for i, _ in enumerate(intervals):\n",
    "                    if i == len(intervals) - 1:\n",
    "                        break\n",
    "                    low = intervals[i]\n",
    "                    high = intervals[i + 1]\n",
    "                    for index, _ in enumerate(columnData[idx]):\n",
    "                        if columnData[idx][index] >= low and columnData[idx][index] < high + 0.000001:\n",
    "                            columnData[idx][index] = label\n",
    "                    label += 1\n",
    "            columnData[idx] = columnData[idx].astype(int)\n",
    "        return np.transpose(columnData)\n",
    "\n",
    "    def __getFeatureNames(self, n_features):\n",
    "        colNames = []\n",
    "        for i in range(0, n_features):\n",
    "            colNames.append(f'Feature_{str(i + 1)}')\n",
    "        return colNames\n",
    "\n",
    "    def __initiateTrainTestSplit(self, dataset, test_size):\n",
    "        trainX, testX, trainY, testY = train_test_split(dataset.drop('target', axis = 1) , \n",
    "                                                        dataset['target'], \n",
    "                                                        stratify = dataset['target'], \n",
    "                                                        test_size = test_size)\n",
    "        trainX['target'] = trainY\n",
    "        testX['target'] = testY\n",
    "        train = trainX.reset_index(drop = True)\n",
    "        test = testX.reset_index(drop = True)\n",
    "        return train, test\n",
    "    \n",
    "    def __induceBias(self, dataset):\n",
    "        df = copy.deepcopy(dataset)\n",
    "        for i, _ in enumerate(df['Feature_1']):\n",
    "            if df['Feature_1'][i] == 1 and df['target'][i] == 0:\n",
    "                if random.uniform(0, 1) >= 0.5:\n",
    "                    df.at[i, 'target'] = 1\n",
    "        return df\n",
    "\n",
    "    def __generateSynDataset(self, n_instances, n_features, cardinality = 2, test_size = 0.2):\n",
    "        syn = make_classification(n_samples = n_instances,\n",
    "                                  n_features = n_features,\n",
    "                                  n_informative = n_features,\n",
    "                                  n_redundant = 0,\n",
    "                                  n_repeated = 0,\n",
    "                                  n_classes = 2,\n",
    "                                  random_state = self.random_state)\n",
    "        data = self.__establishCardinality(data = syn[0],\n",
    "                                           cardinality = cardinality)\n",
    "        target = syn[1]\n",
    "        df = pd.DataFrame(data, columns = self.__getFeatureNames(n_features))\n",
    "        df['target'] = target.tolist()\n",
    "        df = self.__induceBias(df)\n",
    "        train, test = self.__initiateTrainTestSplit(df, test_size)\n",
    "        return train, test\n",
    "    \n",
    "    def __recordTimeTakeByFairDebugger(self, train_save_path, test_save_path):\n",
    "        start = time.time()\n",
    "        dataloader = self.SyntheticDatasetLoader(rootTrain = train_save_path,\n",
    "                                                 rootTest = test_save_path)\n",
    "        fairnessDebug = FairnessDebuggingUsingMachineUnlearning(dataloader,\n",
    "                                                                [\"Feature_1\", 1, 0],\n",
    "                                                                \"target\",\n",
    "                                                                FairnessMetric.PP)\n",
    "        biasedSubsets = fairnessDebug.latticeSearchSubsets(3, (0.05, 0.15), \"normal\", True)\n",
    "        end = time.time()\n",
    "        time_taken = end - start\n",
    "        return time_taken\n",
    "        \n",
    "    '''Main Functions to start the testing'''\n",
    "    def testFairDebuggerForBinaryDatasets(self, dataset_test_size = 0.2):\n",
    "        print(f'All experiment synthetic dataset will have {str(dataset_test_size * 100)}% as test size.')\n",
    "        result = pd.DataFrame(columns = [\"n_instances\", \"n_features\", \"Time Taken(s)\"])\n",
    "        for n_instances in range(self.inst_rng[0], self.inst_rng[1], self.inst_rng[2]):\n",
    "            if n_instances == 0:\n",
    "                continue\n",
    "            for n_features in range(self.feat_rng[0], self.feat_rng[1], self.feat_rng[2]):\n",
    "                if n_features == 0:\n",
    "                    continue\n",
    "                if n_instances == 200000 and n_features == 10:\n",
    "                    continue\n",
    "                print(f'Starting experiment for dataset having {str(n_instances)} instances and {str(n_features)} features.')\n",
    "                train, test = self.__generateSynDataset(n_instances = n_instances,\n",
    "                                                        n_features = n_features,\n",
    "                                                        cardinality = 2,\n",
    "                                                        test_size = dataset_test_size)\n",
    "                train_save_path = f'{self.root_save_path}/train_{str(n_instances)}_inst_{str(n_features)}_feat.csv'\n",
    "                test_save_path = f'{self.root_save_path}/test_{str(n_instances)}_inst_{str(n_features)}_feat.csv'\n",
    "                train.to_csv(train_save_path, index = False)\n",
    "                test.to_csv(test_save_path, index = False)\n",
    "                time_taken = self. __recordTimeTakeByFairDebugger(train_save_path = train_save_path,\n",
    "                                                                  test_save_path = test_save_path)\n",
    "                print(f'Ended experiment after {str(time_taken)} seconds. \\n')\n",
    "                result.loc[len(result)] = [str(n_instances), str(n_features), str(time_taken)]\n",
    "        return result\n",
    "    \n",
    "    def testFairDebuggerForCardinalityVariation(self, n_features, n_instances, cardinality_range, dataset_test_size = 0.2):\n",
    "        print(f'All experiment synthetic dataset will have {str(dataset_test_size * 100)}% as test size.')\n",
    "        result = pd.DataFrame(columns = [\"cardinality\", \"Time Taken(s)\"])\n",
    "        print(f'All datasets are having {str(n_instances)} instances and {str(n_features)} features.')\n",
    "        for cardinality in range(cardinality_range[0], cardinality_range[1], cardinality_range[2]):\n",
    "            print(f'Starting experiment with cardinality = {str(cardinality)}')\n",
    "            train, test = self.__generateSynDataset(n_instances = n_instances,\n",
    "                                                        n_features = n_features,\n",
    "                                                        cardinality = cardinality,\n",
    "                                                        test_size = dataset_test_size)\n",
    "            train_save_path = f'{self.root_save_path}/train_{str(n_instances)}_inst_{str(n_features)}_feat_{str(cardinality)}_cardinality.csv'\n",
    "            test_save_path = f'{self.root_save_path}/test_{str(n_instances)}_inst_{str(n_features)}_feat_{str(cardinality)}_cardinality.csv'\n",
    "            train.to_csv(train_save_path, index = False)\n",
    "            test.to_csv(test_save_path, index = False)\n",
    "            time_taken = self. __recordTimeTakeByFairDebugger(train_save_path = train_save_path,\n",
    "                                                              test_save_path = test_save_path)\n",
    "            print(f'Ended experiment after {str(time_taken)} seconds. \\n')\n",
    "            result.loc[len(result)] = [str(cardinality), str(time_taken)]\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7843e27a",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8eb3d87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tester = FairDebuggerEfficiencyTestWithSyntheticData(n_instances_range = [0, 500001, 50000],\n",
    "                                                     n_features_range = [0, 31, 10],\n",
    "                                                     root_save_path = \"Dataset/Synthetic_Datasets\",\n",
    "                                                     random_state = 18)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9662595b",
   "metadata": {},
   "source": [
    "# Time taken vs # Instances and Time taken vs # Features (binary cardinality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c278d07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = tester.testFairDebuggerForBinaryDatasets()\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d04f3d7",
   "metadata": {},
   "source": [
    "# Time taken vs Feature Cardinality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "960d7823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All experiment synthetic dataset will have 20.0% as test size.\n",
      "All datasets are having 30000 instances and 10 features.\n",
      "Starting experiment with cardinality = 2\n",
      "level: 0\n",
      "level: 1\n",
      "level: 2\n",
      "Ended experiment after 131.44649481773376 seconds. \n",
      "\n",
      "Starting experiment with cardinality = 3\n",
      "level: 0\n",
      "level: 1\n",
      "level: 2\n",
      "Ended experiment after 116.22117853164673 seconds. \n",
      "\n",
      "Starting experiment with cardinality = 4\n",
      "level: 0\n",
      "level: 1\n",
      "level: 2\n",
      "Ended experiment after 77.3833589553833 seconds. \n",
      "\n",
      "Starting experiment with cardinality = 5\n",
      "level: 0\n",
      "level: 1\n",
      "level: 2\n",
      "Ended experiment after 111.20417380332947 seconds. \n",
      "\n",
      "Starting experiment with cardinality = 6\n",
      "level: 0\n",
      "level: 1\n",
      "level: 2\n",
      "Ended experiment after 87.72816944122314 seconds. \n",
      "\n",
      "Starting experiment with cardinality = 7\n",
      "level: 0\n",
      "level: 1\n",
      "level: 2\n",
      "Ended experiment after 106.73000502586365 seconds. \n",
      "\n",
      "Starting experiment with cardinality = 8\n",
      "level: 0\n",
      "level: 1\n",
      "level: 2\n",
      "Ended experiment after 89.0462875366211 seconds. \n",
      "\n",
      "Starting experiment with cardinality = 9\n",
      "level: 0\n",
      "level: 1\n",
      "level: 2\n",
      "Ended experiment after 136.9672257900238 seconds. \n",
      "\n",
      "Starting experiment with cardinality = 10\n",
      "level: 0\n",
      "level: 1\n",
      "level: 2\n",
      "Ended experiment after 147.91204047203064 seconds. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "result2 = tester.testFairDebuggerForCardinalityVariation(n_features = 10,\n",
    "                                                         n_instances = 30000, \n",
    "                                                         cardinality_range = [2, 11, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5939a205",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cardinality</th>\n",
       "      <th>Time Taken(s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>131.44649481773376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>116.22117853164673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>77.3833589553833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>111.20417380332947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>87.72816944122314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>106.73000502586365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>89.0462875366211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9</td>\n",
       "      <td>136.9672257900238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>147.91204047203064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  cardinality       Time Taken(s)\n",
       "0           2  131.44649481773376\n",
       "1           3  116.22117853164673\n",
       "2           4    77.3833589553833\n",
       "3           5  111.20417380332947\n",
       "4           6   87.72816944122314\n",
       "5           7  106.73000502586365\n",
       "6           8    89.0462875366211\n",
       "7           9   136.9672257900238\n",
       "8          10  147.91204047203064"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
