{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d30f0055",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import dare\n",
    "import copy\n",
    "import math\n",
    "import random\n",
    "from enum import Enum\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools as it\n",
    "from ctgan import CTGAN\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.datasets import make_classification\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "import urllib.request as urllib\n",
    "from DebugRF import Dataset, FairnessMetric, FairnessDebuggingUsingMachineUnlearning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46818c27",
   "metadata": {},
   "source": [
    "# Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0caa605a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Class for loading and preprocessing german credits dataset'''\n",
    "class GermanCreditDataset(Dataset): \n",
    "    def __init__(self, rootTrain, rootTest):\n",
    "        Dataset.__init__(self, rootTrain = rootTrain, rootTest = rootTest)\n",
    "#         self.train = pd.DataFrame()\n",
    "#         self.test = pd.DataFrame()\n",
    "        self.train = self.trainDataset\n",
    "        self.test = self.testDataset\n",
    "        if 'Unnamed: 0' in self.train.columns:\n",
    "            self.train.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "        self.__renameColumnNames()\n",
    "#         self.__initiateTrainTestSplit()\n",
    "        self.trainProcessed, self.testProcessed = self.__preprocessDataset(self.train), self.__preprocessDataset(self.test)\n",
    "        self.trainLattice, self.testLattice = self.__preprocessDatasetForCategorization(self.train), self.__preprocessDatasetForCategorization(self.test)\n",
    "        \n",
    "    def getDataset(self):\n",
    "        return self.dataset, self.train, self.test\n",
    "\n",
    "    def getDatasetWithNormalPreprocessing(self):\n",
    "        return self.trainProcessed, self.testProcessed\n",
    "    \n",
    "    def getDatasetWithCategorizationPreprocessing(self, decodeAttributeValues = False):\n",
    "        if decodeAttributeValues == True:\n",
    "            return self.__decodeAttributeCodeToRealValues(self.trainLattice), self.__decodeAttributeCodeToRealValues(self.testLattice)\n",
    "        return self.trainLattice, self.testLattice\n",
    "\n",
    "    def __renameColumnNames(self):\n",
    "        columns={'Column1': 'status_chec_acc', \n",
    "                'Column2': 'duration',\n",
    "                'Column3': 'cred_hist',\n",
    "                'Column4': 'purpose',\n",
    "                'Column5': 'cred_amt',\n",
    "                'Column6': 'savings',\n",
    "                'Column7': 'employment',\n",
    "                'Column8': 'intallment_rate',\n",
    "                'Column9': 'status_and_sex',\n",
    "                'Column10': 'debtors',\n",
    "                'Column11': 'present_resi_since',\n",
    "                'Column12': 'property',\n",
    "                'Column13': 'age',\n",
    "                'Column14': 'install_plans',\n",
    "                'Column15': 'housing',\n",
    "                'Column16': 'existing_creds',\n",
    "                'Column17': 'job',\n",
    "                'Column18': 'num_people_liable_to_maint',\n",
    "                'Column19': 'telephone',\n",
    "                'Column20': 'foreign_worker',\n",
    "                'Column21': 'status'}\n",
    "#         self.dataset.rename(columns = columns, inplace = True)\n",
    "        self.train.rename(columns = columns, inplace = True)\n",
    "        self.test.rename(columns = columns, inplace = True)\n",
    "        \n",
    "    def __initiateTrainTestSplit(self):\n",
    "        trainX, testX, trainY, testY = train_test_split(self.dataset.drop('status', axis = 1) , \n",
    "                                                self.dataset['status'], \n",
    "                                                stratify = self.dataset['status'], \n",
    "                                                test_size=0.2)\n",
    "        trainX['status'] = trainY\n",
    "        testX['status'] = testY\n",
    "        self.train = trainX.reset_index(drop = True)\n",
    "        self.test = testX.reset_index(drop = True)\n",
    "\n",
    "    def __preprocessDataset(self, dataset):\n",
    "        df = copy.deepcopy(dataset)\n",
    "        df['status_chec_acc'] = df['status_chec_acc'].map({'A11': 0, 'A12': 1, 'A13': 2, 'A14': 3}).astype(int, errors='ignore')\n",
    "        df['cred_hist'] = df['cred_hist'].map({'A34': 0, 'A33': 1, 'A32': 2, 'A31': 3, 'A30': 4}).astype(int, errors='ignore')\n",
    "        df['savings'] = df['savings'].map({'A61': 0, 'A62': 1, 'A63': 2, 'A64': 3, 'A65': 4}).astype(int)\n",
    "        df['employment'] = df['employment'].map({'A71': 0, 'A72': 1, 'A73': 2, 'A74': 3, 'A75': 4}).astype(int)    \n",
    "        df['sex'] = df['status_and_sex'].map({'A91': 1, 'A92': 0, 'A93': 1, 'A94': 1, 'A95': 0}).astype(int)\n",
    "        df['debtors'] = df['debtors'].map({'A101': 0, 'A102': 1, 'A103': 2}).astype(int)\n",
    "        df['property'] = df['property'].map({'A121': 3, 'A122': 2, 'A123': 1, 'A124': 0}).astype(int)        \n",
    "        df['install_plans'] = df['install_plans'].map({'A141': 1, 'A142': 1, 'A143': 0}).astype(int)    \n",
    "        df = pd.concat([df, pd.get_dummies(df['purpose'], prefix='purpose')],axis=1)\n",
    "        df = pd.concat([df, pd.get_dummies(df['housing'], prefix='housing')],axis=1)\n",
    "        df = pd.concat([df, pd.get_dummies(df['status_and_sex'], prefix='status_and_sex')],axis=1)\n",
    "        df.loc[(df['cred_amt'] <= 2000), 'cred_amt'] = 0\n",
    "        df.loc[(df['cred_amt'] > 2000) & (df['cred_amt'] <= 5000), 'cred_amt'] = 1\n",
    "        df.loc[(df['cred_amt'] > 5000), 'cred_amt'] = 2    \n",
    "        df.loc[(df['duration'] <= 12), 'duration'] = 0\n",
    "        df.loc[(df['duration'] > 12) & (df['duration'] <= 24), 'duration'] = 1\n",
    "        df.loc[(df['duration'] > 24) & (df['duration'] <= 36), 'duration'] = 2\n",
    "        df.loc[(df['duration'] > 36), 'duration'] = 3\n",
    "        df['age'] = df['age'].apply(lambda x : 1 if x > 30 else 0) # 1 if old, 0 if young\n",
    "        df['job'] = df['job'].map({'A171': 0, 'A172': 1, 'A173': 2, 'A174': 3}).astype(int)    \n",
    "        df['telephone'] = df['telephone'].map({'A191': 0, 'A192': 1}).astype(int)\n",
    "        df['foreign_worker'] = df['foreign_worker'].map({'A201': 1, 'A202': 0}).astype(int)\n",
    "        df['status'] = df['status'].map({1: 1, 2: 0}).astype(int, errors='ignore')\n",
    "        df.drop(columns=['purpose', 'status_and_sex','housing'], inplace = True)\n",
    "        '''Moving status column at the end'''\n",
    "        cols = list(df.columns.values) \n",
    "        cols.pop(cols.index('status')) \n",
    "        df = df[cols+['status']]\n",
    "        return df\n",
    "    \n",
    "    def __preprocessDatasetForCategorization(self, dataset):\n",
    "        df = copy.deepcopy(dataset)\n",
    "        non_object_columns = [col for col in df.columns if df[col].dtypes != 'object']\n",
    "        quantiles = self.train[non_object_columns].quantile([0, .25, .5, .75, 1.0], axis = 0)\n",
    "        for col in non_object_columns:\n",
    "            if col == 'age':\n",
    "                df[col] = pd.cut(df[col], \n",
    "                               [quantiles[col][0.0] - 1, 30, quantiles[col][1.0] + 1], \n",
    "                               labels = ['age = young', 'age = old'], \n",
    "                               right = True, \n",
    "                               include_lowest = True)\n",
    "            elif col == 'status':\n",
    "                continue\n",
    "            elif col == 'cred_amt':\n",
    "                df[col] = pd.cut(df[col], \n",
    "                               [0, 1365.50001, 3972.25001, 18424.0001], \n",
    "                               labels = [str(col) + ' = low', str(col) + ' = medium', str(col) + ' = high'], \n",
    "                               right = True, \n",
    "                               include_lowest = True)\n",
    "            else:\n",
    "                df[col] = pd.cut(df[col], \n",
    "                               [quantiles[col][0.0] - 1, quantiles[col][0.50], math.inf], \n",
    "                               labels = [str(col) + ' = low', str(col) + ' = high'], \n",
    "                               right = True, \n",
    "                               include_lowest = True)\n",
    "        df['status'] = df['status'].map({1: 1, 2: 0}).astype(int, errors='ignore')\n",
    "        '''Moving status column at the end'''\n",
    "        cols = list(df.columns.values) \n",
    "        cols.pop(cols.index('status')) \n",
    "        df = df[cols+['status']]\n",
    "        return df\n",
    "    \n",
    "    def __decodeAttributeCodeToRealValues(self, dataset):\n",
    "        df = copy.deepcopy(dataset)\n",
    "        map_code_to_real = {\n",
    "            \"status_chec_acc\": {\n",
    "                \"A11\": \"status_chec_acc = < 0 DM\",\n",
    "                \"A12\": \"status_chec_acc = 0 <=..< 200DM\",\n",
    "                \"A13\": \"status_chec_acc = > =200 DM\",\n",
    "                \"A14\": \"status_chec_acc = no checking account\"\n",
    "            },\n",
    "            \"cred_hist\": {\n",
    "                \"A30\": \"cred_hist = no credits taken / all credits paid back duly\",\n",
    "                \"A31\": \"cred_hist = all credits at this bank paid back duly\",\n",
    "                \"A32\": \"cred_hist = existing credits paid back duly till now\",\n",
    "                \"A33\": \"cred_hist = delay in paying off in the past\",\n",
    "                \"A34\": \"cred_hist = critical account / other credits existing (not at this bank)\"\n",
    "            },\n",
    "            \"purpose\": {\n",
    "                \"A40\": \"purpose = car (new)\",\n",
    "                \"A41\": \"purpose = car (used)\",\n",
    "                \"A42\": \"purpose = furniture/equipment\",\n",
    "                \"A43\": \"purpose = radio/television\",\n",
    "                \"A44\": \"purpose = domestic appliances\",\n",
    "                \"A45\": \"purpose = repairs\",\n",
    "                \"A46\": \"purpose = education\",\n",
    "                \"A47\": \"purpose = vacation - does not exist?\",\n",
    "                \"A48\": \"purpose = retraining\",\n",
    "                \"A49\": \"purpose = business\",\n",
    "                \"A410\": \"purpose = others\"\n",
    "            },\n",
    "            \"savings\": {\n",
    "                \"A61\": \"savings = ..<100 DM\",\n",
    "                \"A62\": \"savings = 100 <= .. < 500 DM\",\n",
    "                \"A63\": \"savings = 500 <= .. < 1000 DM\",\n",
    "                \"A64\" : \"savings = ..>=1000 DM\",\n",
    "                \"A65\": \"unknown/no savings account\"\n",
    "            },\n",
    "            \"employment\": {\n",
    "                \"A71\": \"employment = unemployed\",\n",
    "                \"A72\": \"employment = .. < 1 year\",\n",
    "                \"A73\": \"employment = 1 <= .. < 4 years\",\n",
    "                \"A74\": \"employment = 4 <= .. < 7 years\",\n",
    "                \"A75\": \"employment = .. >= 7 years\"\n",
    "            },\n",
    "            \"status_and_sex\": {\n",
    "                \"A91\": \"status_and_sex = male: divorced/separated\",\n",
    "                \"A92\": \"status_and_sex = female: divorced/separated/married\",\n",
    "                \"A93\": \"status_and_sex = male: single\",\n",
    "                \"A94\": \"status_and_sex = male: married/widowed\",\n",
    "                \"A95\": \"status_and_sex = femaled: single\"\n",
    "            },\n",
    "            \"debtors\": {\n",
    "                \"A101\": \"debtors = none\",\n",
    "                \"A102\": \"debtors = co-applicant\",\n",
    "                \"A103\": \"debtors = guarantor\"\n",
    "            },\n",
    "            \"property\": {\n",
    "                \"A121\": \"property = real estate\",\n",
    "                \"A122\": \"property = building society savings agreement/life insurance\",\n",
    "                \"A123\": \"property = car or other\",\n",
    "                \"A124\": \"property = unknown / no property\"\n",
    "            },\n",
    "            \"install_plans\": {\n",
    "                \"A141\": \"install_plans = bank\",\n",
    "                \"A142\": \"install_plans = stores\",\n",
    "                \"A143\": \"install_plans = none\"\n",
    "            },\n",
    "            \"housing\": {\n",
    "                \"A151\": \"housing = rent\",\n",
    "                \"A152\": \"housing = own\",\n",
    "                \"A153\": \"housing = for free\"\n",
    "            },\n",
    "            \"job\": {\n",
    "                \"A171\": \"job = unemployed / unskilled - non-resident\",\n",
    "                \"A172\": \"job = unskilled - resident\",\n",
    "                \"A173\": \"job = skilled employee / official\",\n",
    "                \"A174\": \"job = management / self-employed / highly qualified employee / officer\" \n",
    "            },\n",
    "            \"telephone\": {\n",
    "                \"A191\": \"telephone = none\",\n",
    "                \"A192\": \"telephone = yes, registered under customer's name\"\n",
    "            },\n",
    "            \"foreign_worker\": {\n",
    "                \"A201\": \"foreign_worker = yes\",\n",
    "                \"A202\": \"foreign_worker = no\"\n",
    "            }\n",
    "        }\n",
    "        object_columns = [col for col in df.columns if df[col].dtypes == 'object']\n",
    "        for col in object_columns:\n",
    "            df[col] = df[col].map(map_code_to_real[col]).fillna(df[col])\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd875dd",
   "metadata": {},
   "source": [
    "# Generating datasets and recording time taken by FairDebugger to process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11efdacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEfficiencyOfFairDebugger(trainRoot):\n",
    "    data = pd.read_csv(trainRoot)\n",
    "    synData = pd.read_csv(trainRoot)\n",
    "    cols = data.columns.values\n",
    "    num_cols = len(cols)\n",
    "    result = pd.DataFrame(columns = [\"Train Dataset Dimension\", \"Time Taken(s)\"])\n",
    "    for num_rows in range(1000, 55000, 1000):\n",
    "        dim = num_rows * num_cols\n",
    "        if num_rows > 1000:\n",
    "            synData = pd.concat([synData, data], axis=0)\n",
    "            synData.reset_index(drop = True, inplace = True)\n",
    "        synData.to_csv(\"Dataset/synData.csv\")\n",
    "        start = time.time()\n",
    "        dataloader = GermanCreditDataset(rootTrain = \"Dataset/synData.csv\",\n",
    "                                         rootTest = \"Dataset/german_test.csv\")\n",
    "        fairnessDebug = FairnessDebuggingUsingMachineUnlearning(dataloader,\n",
    "                                                                [\"age\", 1, 0],\n",
    "                                                                \"status\",\n",
    "                                                                FairnessMetric.PP)\n",
    "        biasedSubsets = fairnessDebug.latticeSearchSubsets(3, (0.05, 0.15), \"normal\", True)\n",
    "        end = time.time()\n",
    "        time_taken = end - start\n",
    "        print(\"Dataset Size = \" + str(num_rows) + \" --------- Time Taken = \" + str(time_taken))\n",
    "        result.loc[len(result)] = [str(dim), str(time_taken)]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7543ba95",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "level: 0\n",
      "level: 1\n",
      "level: 2\n",
      "Dataset Size = 1000 --------- Time Taken = 96.16019201278687\n",
      "level: 0\n",
      "level: 1\n",
      "level: 2\n",
      "Dataset Size = 2000 --------- Time Taken = 133.52141284942627\n",
      "level: 0\n",
      "level: 1\n",
      "level: 2\n",
      "Dataset Size = 3000 --------- Time Taken = 170.69458603858948\n",
      "level: 0\n",
      "level: 1\n",
      "level: 2\n",
      "Dataset Size = 4000 --------- Time Taken = 210.5600037574768\n",
      "level: 0\n",
      "level: 1\n",
      "level: 2\n",
      "Dataset Size = 5000 --------- Time Taken = 255.18216824531555\n",
      "level: 0\n",
      "level: 1\n",
      "level: 2\n",
      "Dataset Size = 6000 --------- Time Taken = 307.28481221199036\n",
      "level: 0\n",
      "level: 1\n",
      "level: 2\n",
      "Dataset Size = 7000 --------- Time Taken = 368.3868217468262\n",
      "level: 0\n",
      "level: 1\n",
      "level: 2\n",
      "Dataset Size = 8000 --------- Time Taken = 441.74828839302063\n",
      "level: 0\n",
      "level: 1\n",
      "level: 2\n",
      "Dataset Size = 9000 --------- Time Taken = 510.079731464386\n",
      "level: 0\n",
      "level: 1\n",
      "level: 2\n",
      "Dataset Size = 10000 --------- Time Taken = 582.1153585910797\n",
      "level: 0\n",
      "level: 1\n",
      "level: 2\n",
      "Dataset Size = 11000 --------- Time Taken = 660.415857553482\n",
      "level: 0\n",
      "level: 1\n",
      "level: 2\n",
      "Dataset Size = 12000 --------- Time Taken = 745.6291425228119\n",
      "level: 0\n",
      "level: 1\n",
      "level: 2\n",
      "Dataset Size = 13000 --------- Time Taken = 830.6883521080017\n",
      "level: 0\n",
      "level: 1\n",
      "level: 2\n",
      "Dataset Size = 14000 --------- Time Taken = 928.4723808765411\n",
      "level: 0\n",
      "level: 1\n",
      "level: 2\n",
      "Dataset Size = 15000 --------- Time Taken = 997.7364823818207\n",
      "level: 0\n",
      "level: 1\n",
      "level: 2\n",
      "Dataset Size = 16000 --------- Time Taken = 1138.0884382724762\n",
      "level: 0\n",
      "level: 1\n",
      "level: 2\n",
      "Dataset Size = 17000 --------- Time Taken = 1264.0370609760284\n",
      "level: 0\n",
      "level: 1\n",
      "level: 2\n",
      "Dataset Size = 18000 --------- Time Taken = 1383.157598733902\n",
      "level: 0\n",
      "level: 1\n",
      "level: 2\n",
      "Dataset Size = 19000 --------- Time Taken = 1491.3861927986145\n",
      "level: 0\n",
      "level: 1\n",
      "level: 2\n",
      "Dataset Size = 20000 --------- Time Taken = 1609.6748404502869\n",
      "level: 0\n",
      "level: 1\n",
      "level: 2\n",
      "Dataset Size = 21000 --------- Time Taken = 1663.7786724567413\n",
      "level: 0\n",
      "level: 1\n",
      "level: 2\n",
      "Dataset Size = 22000 --------- Time Taken = 1815.1230285167694\n",
      "level: 0\n",
      "level: 1\n",
      "level: 2\n",
      "Dataset Size = 23000 --------- Time Taken = 2027.4252140522003\n",
      "level: 0\n",
      "level: 1\n",
      "level: 2\n"
     ]
    }
   ],
   "source": [
    "result = getEfficiencyOfFairDebugger(\"Dataset/german_train.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
